# The following code to create a dataframe and remove duplicated rows is always executed and acts as a preamble for your script: 

# dataset = pandas.DataFrame(title)
# dataset = dataset.drop_duplicates()

# Paste or type your script code here:
common_prepositions=['aboard', 'about', 'above', 'across', 'after', 'against', 'along', 'amid', 'among', 'anti', 'around', 'as', 'at', 'before', 'behind', 'below', 'beneath', 'beside', 'besides', 'between', 'beyond', 'but', 'by', 'concerning', 'considering', 'despite', 'down', 'during', 'except', 'excepting', 'excluding', 'following', 'for', 'from', 'in', 'inside', 'into', 'like', 'minus', 'near', 'of', 'off', 'on', 'onto', 'opposite', 'outside', 'over', 'past', 'per', 'plus', 'regarding', 'round', 'save', 'since', 'than', 'through', 'to', 'toward', 'towards', 'under', 'underneath', 'unlike', 'until', 'up', 'upon', 'versus', 'via', 'with', 'within', 'without', 'Aboard', 'About', 'Above', 'Across', 'After', 'Against', 'Along', 'Amid', 'Among', 'Anti', 'Around', 'As', 'At', 'Before', 'Behind', 'Below', 'Beneath', 'Beside', 'Besides', 'Between', 'Beyond', 'But', 'By', 'Concerning', 'Considering', 'Despite', 'Down', 'During', 'Except', 'Excepting', 'Excluding', 'Following', 'For', 'From', 'In', 'Inside', 'Into', 'Like', 'Minus', 'Near', 'Of', 'Off', 'On', 'Onto', 'Opposite', 'Outside', 'Over', 'Past', 'Per', 'Plus', 'Regarding', 'Round', 'Save', 'Since', 'Than', 'Through', 'To', 'Toward', 'Towards', 'Under', 'Underneath', 'Unlike', 'Until', 'Up', 'Upon', 'Versus', 'Via', 'With', 'Within', 'Without', 'Aboard', 'About', 'Above', 'Across', 'After', 'Against', 'Along', 'Amid', 'Among', 'Anti', 'Around', 'As', 'At', 'Before', 'Behind', 'Below', 'Beneath', 'Beside', 'Besides', 'Between', 'Beyond', 'But', 'By', 'Concerning', 'Considering', 'Despite', 'Down', 'During', 'Except', 'Excepting', 'Excluding', 'Following', 'For', 'From', 'In', 'Inside', 'Into', 'Like', 'Minus', 'Near', 'Of', 'Off', 'On', 'Onto', 'Opposite', 'Outside', 'Over', 'Past', 'Per', 'Plus', 'Regarding', 'Round', 'Save', 'Since', 'Than', 'Through', 'To', 'Toward', 'Towards', 'Under', 'Underneath', 'Unlike', 'Until', 'Up', 'Upon', 'Versus', 'Via', 'With', 'Within', 'Without', 'Aboard', 'About', 'Above', 'Across', 'After', 'Against', 'Along', 'Amid', 'Among', 'Anti', 'Around', 'As', 'At', 'Before', 'Behind', 'Below', 'Beneath', 'Beside', 'Besides', 'Between', 'Beyond', 'But', 'By', 'Concerning', 'Considering', 'Despite', 'Down', 'During', 'Except', 'Excepting', 'Excluding', 'Following', 'For', 'From', 'In', 'Inside', 'Into', 'Like', 'Minus', 'Near', 'Of', 'Off', 'On', 'Onto', 'Opposite', 'Outside', 'Over', 'Past', 'Per', 'Plus', 'Regarding', 'Round', 'Save', 'Since', 'Than', 'Through', 'To', 'Toward', 'Towards', 'Under', 'Underneath', 'Unlike', 'Until', 'Up', 'Upon', 'Versus', 'Via', 'With', 'Within', 'Without']

common_conjunction=['for','For','And','and','Or','or','So','so','Nor','nor','but','But','yet','Yet','After','after','as','As','now','Now','even','Even','where','Where','Whether','whether','why','Why','while','While','Before','before','unless','Unless']

common_articles=['a','A','An','an','The','the']

common_words_in_titles=['is','Is','How','how','what','What','i','I','your','Your']

common_pre_conj_art=common_prepositions+common_conjunction+common_articles+common_words_in_titles
to_drop=list(dataset[dataset.title.str.contains('Google')].title.index)
dataset.drop(to_drop,inplace=True)

import re
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
def word_counter(x):
    str='.'
    for i in list(x.index):
       str=str+' '+x[i]
    val = re.split("\s", str)
    for i in range(len(val)):
     match=re.search(r'[A-Za-z]',val[i])
     if(match):
        continue
     else:
        val[i]=''
    while(val.count('')!=0):
        val.remove('')
    for i in val:
      for j in common_pre_conj_art:
       if(i==j):
          while(val.count(i)!=0):
           val.remove(i)

    val=pd.Series(val)
    val=val.value_counts()[:30]
    
    wc=WordCloud(width=500,height=280,background_color='#DCDCDC').generate_from_frequencies(val)
    plt.imshow(wc)
    plt.axis('off')
    plt.tight_layout(pad=0, w_pad=0, h_pad=0)
    plt.show()

word_counter(dataset.title)